# 職務経歴書

## 基本情報

| key      | value      |
| -------- | ---------- |
| 氏名     | 鈴木 康輔  |
| 生年月日 | 1991/06/13 |

## スキル・経験

- Python, Django での Web・業務システム開発
- BigQuery, Jupyter, Plotly, Dash, Docker でビッグデータ分析・基盤構築・可視化
- 分析結果に基づく方針の提案・策定・レポーティング
- React.js + TypeScript でのフロントエンド開発
- GAS を利用した社内ツールの作成

| カテゴリ                   | 技術・ツール                                                                                                      |
|--------------------------|-----------------------------------------------------------------------------------------------------------------|
| プログラミング言語・フレームワーク | Python, Django, JavaScript/TypeScript, React.js, Google App Script (GAS), Java                                   |
| データ分析・可視化           | Jupyter, Plotly, Streamlit, BigQuery                                                                             |
| スクレイピング・テスト自動化     | Selenium, BeautifulSoup, Playwright                                                                              |
| データベース                | MySQL, PostgreSQL, Elasticsearch                                                                                 |
| クラウド (AWS)              | EC2, S3, Lambda, RDS, Redshift, CloudFormation, CloudWatch                                                       |
| クラウド (GCP)              | BigQuery, GCS                                                                                                    |
| 管理・コラボレーション         | Git, GitHub, SourceTree, Docker, Kubernetes, VSCode, Slack, Google Meet, Microsoft Teams, Notion, Backlog, Jira, Figma, Swagger |
| 語学        | ・日本語：ネイティブ<br>・英語：TOEIC865 点、日英が 50-50 の環境で半年間の開発経験あり（会議・コメント・ドキュメント・チャット等）<br>・独：簡単な読み書きと日常会話
| その他                    | ・[KARTE（レコメンドシステム）](https://karte.io/)におけるレコメンドの PDCA、分析と実装<br>・ETL 処理のバッチ化・リファクタリング経験(Python/SQLAlchemy)<br>・語学力を活かし、ブリッジ的ポジションでも活躍可能|
<div style="page-break-before:always"></div>

## 強み

業務へのキャッチアップが早く、変更容易性を意識したコーディングが得意だと自負しています。チームとしてのアウトプットも重視しているので、全体としての効率化が図れるならツールなど作成して貢献することも多いです。「面倒をなくすための面倒」を厭わずにでき、コミュニケーションを取りつつ、リサーチ力を活かした根拠に基づいて仕事を進められるタイプです。

## 弱み

新しいチャレンジを繰り返すことが苦にならない一方で、長期間にわたって同じ作業を続けることはやや苦手です。その場合は未経験の分野にも手を広げて、モチベーションを維持しながらチームに貢献することを意識しています。

## 価値観

前職は大切にしている家族との時間が取りにくく、思い切ってキャリアチェンジしました。未経験でしたが、好奇心とチャレンジ精神を武器にキャッチアップできました。
自分の軸は大切にしつつ、仕事も楽しみながらエンドユーザにしっかり価値を届けられるエンジニアでありたいと思っています。
言いなりに開発するのではなく、ヒアリングの結果や実際のニーズを汲み取って本当に必要なものを作ることを目指しています。「もっと良いものが作れそう！」という時には時間と手間を惜しみません。

## 興味・関心

開発そのものにも興味がありますが、1 人の技術力でこなせることには限界があると思っています。チームや組織としての生産性を高めるほうが圧倒的に楽なはずなので、DevOps や CI/CD にも興味があります。
プロジェクト初期から参画する経験がまだ少ないので、そうしたチャンスがあれば積極的に環境整備に携わってみたいです。
処理の共通化やテスト自動化、チームのリソースが分散しないディレクトリ構成の導入などは普段から率先してやっています。
<div style="page-break-before:always"></div>

## 職務経歴詳細

### 株式会社マクロセンド (2019/10〜現在)

| key      | value                                                                                 |
| -------- | ------------------------------------------------------------------------------------- |
| 事業内容 | 主に Python での Web システム・アプリケーション開発、データ分析・機械学習系の PoC/開発業務 |
| 従業員数 | 30 名                                                                                  |
| 雇用形態 | 正社員                                                                                |
| 職種     | システム開発部                                                                        |

### プロジェクト1
旅行系ECサイトのレコメンド機能開発（2022/02~現在）
#### 詳細
クライアントのサイトを訪れるユーザの行動データを分析し、各ユーザへ動的に
おすすめ施設をレコメンドしてUXやCTR/CVRの向上を図るプロジェクト
##### クライアントの課題

- クラウド上に点在して格納されているユーザ行動データを解析して活用したい
- 分析結果を利用して
  - 各ユーザの要求に合ったパーソナライズドレコメンドを提供したい
  - レコメンドに限らず、社内に共有できるビジネス上の有益な知見を得たい

##### 開発メンバー
クライアント（主に）3人、PM1人、PL1人、PG/データサイエンティスト2名（合計7名）
##### プロジェクト内での自分の役割
PG/データサイエンティストとして参画しました。
##### 自身が発揮したバリュー

- データ分析業務の8割を担当してプロジェクト推進に寄与
  - BigQueryでGoogle Analyticsやレコメンドツールから集約されたビッグデータを分析/集約
  - Jupyter Lab + Dockerで集約したデータ、サイズの小さいデータをさらに分析・整理
  - 分析結果を利用して、PlotlyやDashを用いてインタラクティブに操作可能なレポートを生成
  - 定例会でクライアントに結果報告・ヒアリングを行い、チームとしてのネクストアクションを提案
  - ソースのバグやツールの誤った利用で発生する異常データをキャッチ・分析し、原因を特定（事業部レベルに影響を及ぼすものを2回発 見・特定）
  - レコメンドツールの分析指標を定期的に収集し、検定を行うシステムをSelenium + Jupyterで構築
- 点在する行動データのリレーションを把握し、ドキュメントに整備してチームに共有
- プロジェクトリポジトリの再編成を通じてデータ分析処理を共通化、新任者向けチュートリアル作成
- レコメンドツールの特性上、ソースが分散しデグレの温床となりそうな状況を解決、開発効率をアップ

##### 工夫・意識したこと
迅速かつクライアントのニーズに沿ったレポーティングができるよう、定例会での正確なヒアリングは常に重視しています。一方でクライアントのドメイン知識やプロジェクト内の用語に基づく説明をするなど、相手の手間をなくして重要な情報が伝わりやすいように工夫しています。ただし統計用語などはこの限りでなく、正確に使うようにしています。

PlotlyやDashを主に用いることで、誰でも直接データを操作して分析を深められるようにも工夫しています。クライアントのドメイン知識もお借りすることで、より有益なデータが簡単に発見できる可能性が高まるためです。

列指向なBigQueryの特性を考慮しつつ、レコメンドツールもクエリ量に基づいた課金がなされるため、データの取得期間や利用頻度を考慮してクラウド上にデータを書き出すかなど、ABテストごとにデータ量の節約と効率を意識して分析手順を組み立てています。
とはいえ、次に試したいABテストは何か、利用しているKPIは適切か、そもそも取得しているログデータは正しいのかなどを念頭に置いてタスクを進め、必要であれば関連の分析を追加で合わせて行っています。この辺りのバランス感覚が本プロジェクトにおける強みだと感じています。

PG/データサイエンティストの新着任者に合わせて、cookiecutter-data-scienceというプロジェクトテンプレートを参考にデータ分析リポジトリのディレクトリ構成を全面的に見直し、汎用処理を各.ipynbファイルから参照できるようにしてチームの分析効率を向上させました。
またレコメンドツールの差分管理機能が不十分で、過去に配信したABテストが増えてきてデグレの危険性が高まっていたため、過去のソースを整理してGitに移管してわずかなファイルの更新で今後のABテストに対応できるようにプロセスを改善しました。

##### 成果
プロジェクト開始直後は成果が出なかったものの、チームでのKPI見直しや、ABテストの結果に基づいたレコメンド内容の改善で1%程度のCVR改善が見込めるようになってきました。
<div style="page-break-before:always"></div>

### プロジェクト2
AI-OCR エンジンに入力するテキストデータ前処理機能の開発・高速化
#### 詳細
##### クライアントの課題
OCRエンジンが読み取った複数の銀行帳票データを、PostgreSQLにルールベースで
整形・保存するデータ前処理機能の開発に参画しました。特に

- 銀行や年度ごと異なる整形ルールに対応する必要があるが、テストが自動化されていない
- 既存のデータロード処理が遅く、バッチ処理してもテストサイクルが数時間〜数日かかる
- 顧客機密情報を扱うので開発環境がクローズドで、検索や会議の度に発生するデスクとの往来で開発が遅れている

という課題がありました。

##### 開発メンバー
PM1人、PL2人、バックエンドエンジニア1人、インフラエンジニア1人（計5名）
##### プロジェクト内での自分の役割
バックエンドエンジニアとして参画しました。前任者は私の参画後1ヶ月ほどで離任し
チーム内で他にコーディングできる人間もいなかったため、以後は主にソースを読みながら上述の課題をすべて担当しました。

##### 自身が発揮したバリュー

- 整形ルールの共通処理を抽出して独立モジュールにまとめ、新規ルール対応の工数を削減
- クローズドな開発環境をオープン側にDockerで再現し、Pandas + pytestでテストを自動化
- SQLAlchemyのインサートが遅かったため、分析・改修して500倍以上の高速化を達成
- 並行してAIエンジニアと連携して帳票データのアノテーションや動作テストも一部担当し、開発納期の担保に貢献
- 英語を苦にしなかったため、前任者やOCRエンジンの開発チームなど外国籍メンバーとスムーズにやり取りし、日本人メンバーのコミュニケーションもサポート
- エラーログ解析やストレージ圧迫時のファイル整備、LANの設定変更などの軽微なタスクも対応（基盤構築後、インフラエンジニア離任のため）

##### 工夫・意識したこと
データ整形時の処理は銀行・帳票の種類・年度により異なりますが、共通処理をモジュール化して新規ルール対応時の開発工数を50%以上削減することができました。
また、動作テストは元々クローズドなセキュリティルームで行っていましたが、エラーが出るたびに自身のデスクまで移動して対応策を調べたり実装すべきコードの当たりをつけたりして、修正を施す非効率なサイクルの繰り返しでした。
そこで自身のデスクにDockerコンテナ内に本番環境と同等のPostgreSQLを構築し、取得したETL処理にもPandasを導入して整形処理の可読性を向上させました。また整形ルールをpytestで事前に作成しておくTDDライクな開発手法も取り入れて、クローズド環境へのソースコード持ち込み申請の回数を減らして上長への負担も軽減しつつ開発速度をアップさせました。

##### 成果
参画当初の開発ペースは2,3週間で1ルール程度でしたが、上記の改善により最大1週間で3つのルールに対応できるほど開発効率をアップし、遅れ気味だった納期に間に合わせることができました。
クライアントからは条件面を大幅アップの上で社内メンバーにお誘い頂くなど、高く評価して頂きました。
<div style="page-break-before:always"></div>

### プロジェクト3
化学メーカー様の実験に関する知見をグループ全体で共有するための検索システム開発
#### 詳細
##### クライアントの課題
過去に行った化学実験に関するデータや知見が社内で十分に共有できておらず、似た実験が繰り返されている現状を課題に感じられていました。そのため、化合物データを一元的に管理・可視化できるシステムの構築を業務委託されました。
##### 開発メンバー
PM1人、PL1人、PG2人（計4名）

##### チームとしての提案
基本的な機能を有するプロトタイプ開発を行い、スモールスタートでの導入を提案しました。
3ヶ月の初期契約完了後に、継続的な開発・運用・保守についてご検討頂く方針となりました。

##### プロジェクト内での自身の役割
PGとして参画し、主に以下の工程を担当しました。

- 画面モックの作成(Figma)
- 画面の実装および動作テスト(React + TypeScript)
- 表示データを取得・保存するAPIの改修(AWS Lambda, RDS, Python, SQLAlchemy)

##### 自身が発揮したバリュー

- 初のフロントエンド開発経験ながら、自身の時間も活用してキャッチアップ
- 画面の共通部分が多かったため、FigmaやReactではコンポーネント機能を活用して工数を削減
- バックエンド処理もReact hookを用いた独自処理を汎用化して開発効率UPに貢献
- AWS LambdaでのサーバレスAPIを実装してコスト低減に貢献、ORMで拡張性も確保

##### 工夫・意識したこと
新たな技術への挑戦をしながらチーム内での進捗を意識して立ち回り、API開発の遅れを巻き取るなど全体を見ながら動くことを常に意識しました。
またフロントエンドまで経験したことで開発の全体像が把握できるようになり、動作速度や開発効率・拡張性などを考慮したスタックの選定にも口を出すようになりました。

##### 成果
プロトタイプの品質にご満足頂き、検索スピードの更なる向上やシステム利用者の規模を段階的に広げる際のオートスケーリングなど、新たな課題のご相談にフェーズを進めることができました。
<div style="page-break-before:always"></div>

### プロジェクト4
センサー、ネットワーク機器から収集したログデータを可視化・異常検知を行うソフトウェアの開発
#### 詳細
##### クライアントの課題
ネットワーク機器の通信ログを収集して可視化・異常検知を行うパッケージシステムの開発を促進するため、参画を依頼されました。
##### 開発メンバー
PM1人、PL1人、PG4人（計6名）
##### 開発方針

- ウォーターフォール開発
- Git-flowに基づくチーム開発

##### プロジェクト内での自身の役割
PGとして参画し、主に以下の工程を担当しました。これがエンジニアとしての初案件でした。

- ログデータの可視化・ラベル編集機能（Python, Django, ElasticSearch, w2ui, Pylance）
- ログデータの検索・ダウンロード・アップロード用REST APIの詳細設計・実装・テスト仕様書の作成およびテスト(Python, Django REST framework, Pylance)

##### 自身が発揮したバリュー

- 詳細設計書に基づいて開発し、静的解析後にGit-flowに従ってプルリクエストを作成してコードレビューを受ける/するという、基本的な開発フローへの習熟
- REST APIの実装は既存処理の改修も含めてチーム内で全面的に担当
- ネットワークログ監視デーモンの動作改善や、可視化グラフのデータを自動でラベルづけするロジックの改修

##### 工夫・意識したこと
従来型のDBを経験することなくElasticsearchというスキーマレスな全文検索エンジンに触れることになり、当初はデータ構造の理解に苦労しました。個人的にもSQLiteを構築してSQLを触ってみることで、対比しながら理解が進むとともに、SQLiteを標準利用しているDjangoにもスムーズに入り込むことができました。

##### 成果
1年半ほど参画し、最終的には基本設計書に基づく技術調査→詳細設計書の作成→実装→テスト仕様書の作成とテスト実施→チームメンバーからのダブルチェック後にQAへのハンドオフというサイクルが回せるようになり、無事に4サイクルほどリリースを迎えることができました。
退場時にはPLからも「キャッチアップが早く助かった」とフィードバックを頂きました。
<div style="page-break-before:always"></div>

### 海上自衛隊 (2015/10〜2019/7)

| key        | value                                                                           |
| ---------- | ------------------------------------------------------------------------------- |
| 任務・活動 | （1）我が国の領域および周辺海域の防衛（2）海上交通の安全確保（3）望ましい安全保障環境の創出 |
| 隊員数     | 45,356 名                                                                       |

神奈川・広島・山口・鹿児島などで勤務し、沢山の珍しい経験ができました。ぜひ直接お話しさせてください！

## 将来どうなりたいか

### 1年後になりたい姿

PL, PM としてのキャリアにも手を広げつつ、バックエンド・インフラへの理解をさらに高めて幅広く活躍したいです。

### 3年後になりたい姿

マイクロサービスに 0 から携わってマネジメントと開発の両輪を回し、プロジェクトを推進できる人材になりたいです。

### 現在となりたい姿とのギャップ

アーキテクチャ設計の経験やインフラ構築、セキュリティに対する理解が不足しているので、それらの技術を理解していく必要があります。また、マネジメントにも取り組むチャンスを貰う前提としての知識・準備をしなければならないと感じます。

### なりたい姿を達成するために、取り組みたいこと

小さなサービスで良いので、スクラッチ開発で一通りの技術に触れる経験をするべきです。また、過去に手がけたデータ分析の手法について自分なりにまとめ、チームにも展開可能な分析基盤を作成することも役立ちそうです。マネジメントについては本を読むのも良いですし、勉強会への参加や資格の取得を目指すなど、関連知識に触れる機会を確保することから取り組みたいです。